{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from twitter.scraper import *\n",
    "from IPython.display import display, HTML\n",
    "import re, pandas as pd, numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm.notebook import tqdm as notebook_tqdm\n",
    "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # show full text in each cell\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "roberta_model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "# sentiment_task = pipeline(\"sentiment-analysis\", model=roberta_model_path, tokenizer=roberta_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta_model_path, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta_model_path)\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import twitter\n",
    "importlib.reload(twitter)\n",
    "from twitter import *\n",
    "from datetime import datetime\n",
    "\n",
    "def relevancy_score(tweet, decay=0.7):\n",
    "    # decay=1.0: linear penalty â†’ each extra day reduces score proportionally.\n",
    "    # Smaller decay (e.g. 0.5) â†’ recency matters less.\n",
    "    # Larger decay (e.g. 2) â†’ recency matters more strongly.\n",
    "    created_at = datetime.strptime(tweet[\"created_at\"], \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    created_at = created_at.replace(tzinfo=None)  # drop tz for consistency\n",
    "    age_days = (datetime.now() - created_at).days + 1   # +1 to avoid div by 0\n",
    "    return tweet[\"replies\"] / (age_days ** decay)\n",
    "\n",
    "def clean_tweet(t):\n",
    "    t = re.sub(r\"http\\S+\", \"\", t)  \n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    if t.startswith('@'):\n",
    "        parts = t.split(\" \", 1)\n",
    "        if len(parts) > 1:\n",
    "            return parts[1]\n",
    "        else:\n",
    "            return t\n",
    "    return t\n",
    "    \n",
    "def stringify_tweet(tweet: Tweet):\n",
    "    full_tweet = []\n",
    "    cleaned_tweet_text = clean_tweet(tweet[\"text\"])\n",
    "    if cleaned_tweet_text: \n",
    "        full_tweet.append(cleaned_tweet_text)\n",
    "    if tweet[\"post_image_description\"]:\n",
    "        full_tweet.append(tweet[\"post_image_description\"])\n",
    "    if tweet[\"post_video_description\"]:\n",
    "        full_tweet.append(tweet[\"post_video_description\"])\n",
    "    \n",
    "    if tweet[\"quoted_tweet\"]:\n",
    "        full_tweet+= [stringify_tweet(tweet[\"quoted_tweet\"])]\n",
    "    return \"\\n\".join(full_tweet)\n",
    "\n",
    "\n",
    "rocket_lab = '91145174'\n",
    "peter_beck = '976574172468936704'\n",
    "nvidia= '61559439'\n",
    "elon_musk = '44196397'\n",
    "\n",
    "tweets = get_user_tweets(rocket_lab, period='days=15')[0]\n",
    "\n",
    "top_20_tweets = sorted(tweets, key=lambda x: relevancy_score(x), reverse=True)[:20]\n",
    "comments = get_comments('1959432404080230691', minimum_comments=200)[0]\n",
    "# comments = get_comments(top_20_tweets[0][\"tweet_id\"], minimum_comments=200)[0]\n",
    "original_tweet = comments[0]\n",
    "comments = comments[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = []\n",
    "cleaned_comments = []\n",
    "clean_comments_obj = []\n",
    "\n",
    "print(f'Tweet count: {len(tweets)}')\n",
    "print(\"Newest Tweet Date: \", tweets[0][\"created_at\"])\n",
    "print(\"Oldest Tweet Date: \", tweets[-1][\"created_at\"])\n",
    "\n",
    "for tweet in tweets:\n",
    "    if tweet[\"retweeted_tweet\"]: continue\n",
    "    full_tweet = stringify_tweet(tweet)\n",
    "    if not full_tweet: continue\n",
    "    cleaned_tweets.append(full_tweet)\n",
    "    # print(full_tweet)\n",
    "    # print(\"-\"*100)\n",
    "\n",
    "print(f\"Cleaned tweet count: {len(cleaned_tweets)}/{len(tweets)}\")\n",
    "print('='*100)\n",
    "\n",
    "# print(top_20_tweets[0])\n",
    "for comment in comments[1:]: # first comment is the original tweet\n",
    "    cleaned_comment = stringify_tweet(comment)\n",
    "    if not cleaned_comment: continue\n",
    "    cleaned_comments.append(cleaned_comment)\n",
    "    clean_comments_obj.append(comment)\n",
    "    print(cleaned_comment)\n",
    "    print(\"-\"*100)\n",
    "\n",
    "print(\"Oldest Comment Date: \", comments[0][\"created_at\"])\n",
    "print(\"Newest Comment Date: \", comments[-1][\"created_at\"])\n",
    "print(f\"{len(cleaned_comments)}/{len(comments[1:])}\")\n",
    "print(len(clean_comments_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rob_score_from_texts(texts: List[str], batch_size: int = 32) -> List[float]:\n",
    "    \"\"\"\n",
    "    Batch inference returning continuous scores in [-1, 1]:\n",
    "    score = prob_pos - prob_neg\n",
    "    For models with 3 labels arranged [negative, neutral, positive].\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i : i + batch_size]\n",
    "            enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "            enc = {k: v.to('cuda') for k, v in enc.items()}\n",
    "            out = model(**enc)\n",
    "            logits = out.logits.cpu()\n",
    "            probs = torch.softmax(logits, dim=-1).numpy()  # shape (batch, num_labels)\n",
    "            # mapping - assumes label order is neg, neu, pos\n",
    "            # if model uses different label order, you must reorder accordingly\n",
    "            for p in probs:\n",
    "                if p.shape[0] == 3:\n",
    "                    prob_neg, prob_neu, prob_pos = p\n",
    "                    score = float(prob_pos - prob_neg)  # in (-1, 1)\n",
    "                elif p.shape[0] == 2:\n",
    "                    # binary model mapping (pos prob - neg prob)\n",
    "                    prob_neg = p[0]\n",
    "                    prob_pos = p[1]\n",
    "                    score = float(prob_pos - prob_neg)\n",
    "                else:\n",
    "                    # fallback: compute (expected label index scaled)\n",
    "                    labels = np.arange(len(p))\n",
    "                    norm = (labels - labels.mean()) / (labels.max() - labels.min() + 1e-9)\n",
    "                    score = float(np.dot(p, norm))\n",
    "                    # then scale to -1..1\n",
    "                    score = max(-1.0, min(1.0, score))\n",
    "                scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def combine_scores(roberta_scores, vader_scores, roberta_weight=0.7, vader_weight=0.3):\n",
    "    \"\"\"\n",
    "    Vectorized combination of RoBERTa and VADER sentiment scores (both in [-1, 1]).\n",
    "    - If models strongly disagree (|diff|>0.6) or VADER is 0, trust RoBERTa.\n",
    "    - When signs disagree, upweight RoBERTa (0.9/0.1) and apply disagreement damping.\n",
    "    Returns a list of combined scores in [-1, 1].\n",
    "    \"\"\"\n",
    "    sR = np.asarray(roberta_scores, dtype=float)\n",
    "    sV = np.asarray(vader_scores, dtype=float)\n",
    "    wR = np.full_like(sR, float(roberta_weight))\n",
    "    wV = np.full_like(sR, float(vader_weight))\n",
    "\n",
    "    diff = np.abs(sR - sV)\n",
    "    strong_mask = (diff > 0.6) | (sV == 0.0) # strong disagreement or VADER is exactly neutral â†’ trust RoBERTa\n",
    "    \n",
    "    # if disagree, upweight RoBERTa and dampen\n",
    "    sign_disagree = (sR * sV) < 0.0 \n",
    "    wR = np.where(sign_disagree, 0.9, wR)\n",
    "    wV = np.where(sign_disagree, 0.1, wV)\n",
    "    damp_factor = np.ones_like(sR, dtype=float)\n",
    "    damp_factor = np.where(sign_disagree, 1.0 - 0.5 * np.minimum(diff, 1.0), damp_factor)\n",
    "\n",
    "    combined = (wR * sR + wV * sV) / (wR + wV)\n",
    "    combined = combined * damp_factor\n",
    "    combined = np.where(strong_mask, sR, combined)\n",
    "\n",
    "    combined = np.clip(combined, -1.0, 1.0)\n",
    "    return combined.tolist()\n",
    "\n",
    "vader_sentiments = [analyzer.polarity_scores(sentence)[\"compound\"] for sentence in cleaned_comments]\n",
    "roberta_sentiments = rob_score_from_texts(cleaned_comments)\n",
    "combined_scores = combine_scores(roberta_sentiments, vader_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame()\n",
    "sentiment_df[\"comment\"] = cleaned_comments\n",
    "sentiment_df[\"likes\"] = [tweet[\"likes\"] for tweet in clean_comments_obj]\n",
    "sentiment_df[\"roberta\"] = roberta_sentiments\n",
    "sentiment_df[\"vader\"] = vader_sentiments\n",
    "sentiment_df[\"combined\"] = combined_scores\n",
    "sentiment_df['combined'] = (sentiment_df['combined'] + 1) / 2\n",
    "eps = 1e-9\n",
    "weighted_likes = np.log1p(sentiment_df['likes']) + eps\n",
    "weighted_normalised_likes = weighted_likes / np.linalg.norm(weighted_likes)\n",
    "sentiment_df['weighted_likes'] = weighted_normalised_likes\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"Overall sentiment: {np.average(sentiment_df['combined'], weights=weighted_normalised_likes)}\")\n",
    "display(HTML(sentiment_df.to_html(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_df = pd.DataFrame()\n",
    "sign_map = {\"positive\": 1.0, \"neutral\": 0.0, \"negative\": -1.0}\n",
    "labels = {\"negative\": \"âŒ\", \"neutral\": \"ðŸ˜\", \"positive\": \"âœ…\"}\n",
    "roberta_df[\"label\"] = [labels[sentiment[\"label\"]] for sentiment in roberta_sentiments]\n",
    "roberta_df[\"sentiment\"] = [sign_map[sentiment[\"label\"]] for sentiment in roberta_sentiments]\n",
    "roberta_df[\"confidence\"] = [sentiment[\"score\"] for sentiment in roberta_sentiments]\n",
    "roberta_df[\"comment\"] = cleaned_comments\n",
    "roberta_df[\"likes\"] = [c[\"likes\"] for c in clean_comments_obj]\n",
    "\n",
    "likes = roberta_df[\"likes\"].astype(float)\n",
    "M = np.log1p(likes.max()) if likes.max() > 0 else 1.0\n",
    "norm_log = np.log1p(likes) / M\n",
    "baseline = 0.3\n",
    "roberta_df[\"weight_likes\"] = baseline + (1 - baseline) * norm_log\n",
    "\n",
    "# per-row polarity in [-1, 1]\n",
    "roberta_df[\"polarity\"] = roberta_df[\"sentiment\"] * roberta_df[\"confidence\"]\n",
    "\n",
    "# overall weighted sentiment in [-1, 1]\n",
    "overall = np.average(roberta_df[\"polarity\"], weights=roberta_df[\"weight_likes\"])\n",
    "print(\"Overall weighted sentiment (âˆ’1..1):\", overall)\n",
    "print(\"As % positive tilt (0..100):\", (overall + 1) * 50)\n",
    "\n",
    "# optionally exclude neutrals (sentiment == 0)\n",
    "non_neutral = roberta_df[\"sentiment\"] != 0\n",
    "overall_non_neu = np.average(\n",
    "    roberta_df.loc[non_neutral, \"polarity\"],\n",
    "    weights=roberta_df.loc[non_neutral, \"weight_likes\"]\n",
    ")\n",
    "print(\"Weighted sentiment excl. neutral (âˆ’1..1):\", overall_non_neu)\n",
    "print(\"As % positive tilt excl. neutral:\", (overall_non_neu + 1) * 50)\n",
    "\n",
    "# quick breakdown to see which side drives the score\n",
    "tmp = roberta_df.assign(weighted_contrib=roberta_df[\"polarity\"] * roberta_df[\"weight_likes\"])\n",
    "print(\n",
    "    tmp.groupby(\"label\")\n",
    "       .agg(total_weight=(\"weight_likes\",\"sum\"),\n",
    "            contrib_sum=(\"weighted_contrib\",\"sum\"))\n",
    "       .sort_values(\"contrib_sum\", ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "roberta_df[\"polarity\"] = roberta_df[\"confidence\"] * roberta_df[\"weight_likes\"] * roberta_df[\"sentiment\"]\n",
    "non_neutral = roberta_df[\"sentiment\"] != 0\n",
    "\n",
    "# print(roberta_sentiments)\n",
    "# print(aggregate_label_conf(roberta_sentiments))\n",
    "\n",
    "print(roberta_df.groupby(\"label\").size())\n",
    "# print(non_neutral.groupby(\"label\").size())\n",
    "\n",
    "pos = (roberta_df[\"sentiment\"] > 0).sum()\n",
    "neg = (roberta_df[\"sentiment\"] < 0).sum()\n",
    "neu = (roberta_df[\"sentiment\"] == 0).sum()\n",
    "total = len(roberta_df)\n",
    "\n",
    "pprint({\n",
    "    \"pos%\": float(pos/total)*100,\n",
    "    \"neg%\": float(neg/total)*100,\n",
    "    \"neu%\": float(neu/total)*100,\n",
    "})\n",
    "print(\"Excluding neutral comments\")\n",
    "pprint({\n",
    "    \"pos%\": float(pos/(total-neu))*100,\n",
    "    \"neg%\": float(neg/(total-neu))*100,\n",
    "})\n",
    "negative_comments = roberta_df[roberta_df[\"sentiment\"] == \"âŒ\"]\n",
    "positive_comments = roberta_df[roberta_df[\"sentiment\"] == \"âœ…\"]\n",
    "neutral_comments = roberta_df[roberta_df[\"sentiment\"] == \"ðŸ˜\"]\n",
    "roberta_df.sort_values(by=\"likes\", ascending=False, inplace=True)\n",
    "\n",
    "# display(HTML(negative_comments.to_html(index=False)))\n",
    "# display(HTML(positive_comments.to_html(index=False)))\n",
    "# display(HTML(neutral_comments.to_html(index=False)))\n",
    "display(HTML(roberta_df.to_html(index=False, max_rows=30)))\n",
    "# display(HTML(roberta_df[non_neutral].to_html(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "representation_model = OpenAI(client, model=\"gpt-4o\", chat=True)\n",
    "openai_BertTopic_model = BERTopic(representation_model=representation_model)\n",
    "\n",
    "representation_model = KeyBERTInspired()\n",
    "keybert_BertTopic_model = BERTopic(representation_model=representation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e414d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic fitting\n",
    "keybert_topics, keybert_probs = keybert_BertTopic_model.fit_transform(cleaned_tweets)\n",
    "keybert_topic_info = keybert_BertTopic_model.get_topic_info()  # topic list with sizes\n",
    "keybert_topic_info\n",
    "\n",
    "\n",
    "openai_topics, openai_probs = openai_BertTopic_model.fit_transform(cleaned_tweets)\n",
    "openai_topic_model = openai_BertTopic_model.reduce_topics(cleaned_tweets, nr_topics=\"auto\")\n",
    "openai_topic_info = openai_BertTopic_model.get_topic_info()  # topic list with sizes\n",
    "openai_topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49480502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vader_df = pd.DataFrame()\n",
    "vader_df[\"comment\"] = cleaned_comments\n",
    "vader_sentiments = [analyzer.polarity_scores(sentence) for sentence in cleaned_comments]\n",
    "# vader_df[\"neg\"] = [sentiment[\"neg\"] for sentiment in vader_sentiments]\n",
    "# vader_df[\"neu\"] = [sentiment[\"neu\"] for sentiment in vader_sentiments]\n",
    "# vader_df[\"pos\"] = [sentiment[\"pos\"] for sentiment in vader_sentiments]\n",
    "# vader_df[\"compound\"] = [sentiment[\"compound\"] for sentiment in vader_sentiments]\n",
    "vader_df[\"overall\"] = [[\"âŒ\", \"ðŸ˜\", \"âœ…\"][np.argmax([sentiment[\"neg\"], sentiment[\"neu\"], sentiment[\"pos\"]])] for sentiment in vader_sentiments]\n",
    "vader_df[\"confidence\"] = [sentiment[[\"neg\", \"neu\", \"pos\"][np.argmax([sentiment[\"neg\"], sentiment[\"neu\"], sentiment[\"pos\"]])]] for sentiment in vader_sentiments]\n",
    "print(vader_df.groupby(\"overall\").size())\n",
    "vader_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "qwen3 = ChatOllama(model=\"qwen3:14b\")\n",
    "llama3_1 = ChatOllama(model=\"llama3.1:8b\")\n",
    "mistral = ChatOllama(model=\"mistral:7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd984020",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = f\"\"\"\n",
    "Perform sentiment analysis on the tweet and comments.  \n",
    "\n",
    "- Give Overall sentiment: <SCORE from -1 to 1>.  \n",
    "\n",
    "Input:  \n",
    "Tweet: {stringify_tweet(top_20_tweets[0])}  \n",
    "Comments: {json.dumps(cleaned_comments)}  \n",
    "\"\"\".strip()\n",
    "\n",
    "res = llama3_1.invoke(test_prompt)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6dd312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "futures = []\n",
    "with ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    for comment in cleaned_comments:\n",
    "        futures.append(executor.submit(llama3_1.invoke, f\"Please give a sentiment analysis of the following comment: {comment}\"))\n",
    "\n",
    "for future in futures:\n",
    "    res = future.result()\n",
    "    print(res.content)\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d132b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
